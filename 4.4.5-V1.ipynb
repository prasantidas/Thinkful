{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import movie_reviews, stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg/cv000_29416.txt',\n",
       " 'neg/cv001_19502.txt',\n",
       " 'neg/cv002_17424.txt',\n",
       " 'neg/cv003_12683.txt',\n",
       " 'neg/cv004_12641.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.fileids('neg')[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pos/cv000_29590.txt',\n",
       " 'pos/cv001_18431.txt',\n",
       " 'pos/cv002_15918.txt',\n",
       " 'pos/cv003_11664.txt',\n",
       " 'pos/cv004_11636.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.fileids('pos')[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pick 2 files, one from positive review and one from negative review\n",
    "neg_rev_list = []\n",
    "for i in movie_reviews.fileids('neg')[0:5]:\n",
    "    #print(i)\n",
    "    neg_rev_list.append(movie_reviews.raw(i))\n",
    "all_neg_revs = ' '.join(neg_rev_list)\n",
    "\n",
    "pos_rev_list = []\n",
    "for i in movie_reviews.fileids('pos')[0:5]:\n",
    "    #print(i)\n",
    "    pos_rev_list.append(movie_reviews.raw(i))\n",
    "all_pos_revs = ' '.join(pos_rev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15612"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_neg_revs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20738"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_pos_revs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plot : two teen couples go to a church party , drink and then drive . \\nthey get into an accident . \\none of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \\nwhat\\'s the deal ? \\nwatch the movie and \" sorta \" find out . . . \\ncritique : a mind-fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package . \\nwhich is what makes this review an even harder one to write , since i generally applaud films which attempt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_neg_revs[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"films adapted from comic books have had plenty of success , whether they're about superheroes ( batman , superman , spawn ) , or geared toward kids ( casper ) or the arthouse crowd ( ghost world ) , but there's never really been a comic book like from hell before . \\nfor starters , it was created by alan moore ( and eddie campbell ) , who brought the medium to a whole new level in the mid '80s with a 12-part series called the watchmen . \\nto say moore and campbell thoroughly researched the subject\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pos_revs[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    \n",
    "    text = ' '.join(text.split())\n",
    "    text = re.sub(r' . . . ','. ',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_rev_clean = text_cleaner(all_neg_revs)\n",
    "neg_rev_all_clean = neg_rev_clean.replace(\"\\\\\",'')\n",
    "\n",
    "pos_rev_clean = text_cleaner(all_pos_revs)\n",
    "pos_rev_all_clean = pos_rev_clean.replace(\"\\\\\",'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plot : two teen couples go to a church party , drink and then drive . \\nthey get into an accident . \\none of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \\nwhat\\'s the deal ? \\nwatch the movie and \" sorta \" find out . . . \\ncritique : a mind-fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package . \\nwhich is what makes this review an even harder one to write , since i generally applaud films which attempt'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_neg_revs[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot : two teen couples go to a church party , drink and then drive . they get into an accident . one of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . what's the deal ? watch the movie and \" sorta \" find out. critique : a mind-fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package . which is what makes this review an even harder one to write , since i generally applaud films which attempt to break t\n"
     ]
    }
   ],
   "source": [
    "print(neg_rev_all_clean[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"films adapted from comic books have had plenty of success , whether they're about superheroes ( batman , superman , spawn ) , or geared toward kids ( casper ) or the arthouse crowd ( ghost world ) , but there's never really been a comic book like from hell before . \\nfor starters , it was created by alan moore ( and eddie campbell ) , who brought the medium to a whole new level in the mid '80s with a 12-part series called the watchmen . \\nto say moore and campbell thoroughly researched the subject\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pos_revs[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "films adapted from comic books have had plenty of success , whether they're about superheroes ( batman , superman , spawn ) , or geared toward kids ( casper ) or the arthouse crowd ( ghost world ) , but there's never really been a comic book like from hell before . for starters , it was created by alan moore ( and eddie campbell ) , who brought the medium to a whole new level in the mid '80s with a 12-part series called the watchmen . to say moore and campbell thoroughly researched the subject o\n"
     ]
    }
   ],
   "source": [
    "print(pos_rev_all_clean[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse using SpaCy\n",
    "nlp = spacy.load('en')\n",
    "neg_rev_doc = nlp(neg_rev_all_clean)\n",
    "pos_rev_doc = nlp(pos_rev_all_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(plot, :, two, teen, couples, go, to, a, churc...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(they, get, into, an, accident, .)</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(one, of, the, guys, dies, ,, but, his, girlfr...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(what, 's, the, deal, ?)</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(watch, the, movie, and, \", sorta, \")</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0         1\n",
       "0  (plot, :, two, teen, couples, go, to, a, churc...  Negative\n",
       "1                 (they, get, into, an, accident, .)  Negative\n",
       "2  (one, of, the, guys, dies, ,, but, his, girlfr...  Negative\n",
       "3                           (what, 's, the, deal, ?)  Negative\n",
       "4              (watch, the, movie, and, \", sorta, \")  Negative"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group into sentences\n",
    "neg_sents = [ [sent,'Negative'] for sent in neg_rev_doc.sents]\n",
    "pos_sents = [[sent, 'Positive'] for sent in pos_rev_doc.sents]\n",
    "\n",
    "\n",
    "sentences_df = pd.DataFrame(neg_sents + pos_sents)\n",
    "sentences_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(295, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create bag of words function for each text\n",
    "def bag_of_words(text, most_common_count):\n",
    "    \n",
    "    # filter out punctuation and stop words\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    print('allwords count', len(allwords))\n",
    "    # Return most common words\n",
    "    return [item[0] for item in Counter(allwords).most_common(most_common_count)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allwords count 2716\n",
      "allwords count 3511\n"
     ]
    }
   ],
   "source": [
    "# Get bags \n",
    "neg_words = bag_of_words(neg_rev_doc, 500)\n",
    "\n",
    "pos_words = bag_of_words(pos_rev_doc, 500)\n",
    "\n",
    "# Combine bags to create common set of unique words\n",
    "common_words = set(neg_words + pos_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create bag of words data frame using combined common words and sentences\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Build data frame\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentences in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentences\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>craziness</th>\n",
       "      <th>dig</th>\n",
       "      <th>really</th>\n",
       "      <th>20</th>\n",
       "      <th>reformed</th>\n",
       "      <th>against</th>\n",
       "      <th>dragon</th>\n",
       "      <th>either</th>\n",
       "      <th>chan</th>\n",
       "      <th>type</th>\n",
       "      <th>...</th>\n",
       "      <th>opening</th>\n",
       "      <th>student</th>\n",
       "      <th>base</th>\n",
       "      <th>disappearance</th>\n",
       "      <th>i</th>\n",
       "      <th>call</th>\n",
       "      <th>thing</th>\n",
       "      <th>adequate</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(plot, :, two, teen, couples, go, to, a, churc...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(they, get, into, an, accident, .)</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(one, of, the, guys, dies, ,, but, his, girlfr...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(what, 's, the, deal, ?)</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(watch, the, movie, and, \", sorta, \")</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 827 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  craziness dig really 20 reformed against dragon either chan type  \\\n",
       "0         0   0      0  0        0       0      0      0    0    0   \n",
       "1         0   0      0  0        0       0      0      0    0    0   \n",
       "2         0   0      0  0        0       0      0      0    0    0   \n",
       "3         0   0      0  0        0       0      0      0    0    0   \n",
       "4         0   0      0  0        0       0      0      0    0    0   \n",
       "\n",
       "      ...     opening student base disappearance  i call thing adequate  \\\n",
       "0     ...           0       0    0             0  0    0     0        0   \n",
       "1     ...           0       0    0             0  0    0     0        0   \n",
       "2     ...           0       0    0             0  0    0     0        0   \n",
       "3     ...           0       0    0             0  0    0     0        0   \n",
       "4     ...           0       0    0             0  0    0     0        0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (plot, :, two, teen, couples, go, to, a, churc...    Negative  \n",
       "1                 (they, get, into, an, accident, .)    Negative  \n",
       "2  (one, of, the, guys, dies, ,, but, his, girlfr...    Negative  \n",
       "3                           (what, 's, the, deal, ?)    Negative  \n",
       "4              (watch, the, movie, and, \", sorta, \")    Negative  \n",
       "\n",
       "[5 rows x 827 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create bow features \n",
    "reviews = bow_features(sentences_df, common_words)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(295, 827)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_sents_list = []\n",
    "pos_sents_list = []\n",
    "all_sents_list = []\n",
    "for i in movie_reviews.fileids('neg')[0:5]:\n",
    "    \n",
    "    neg_rev_sents = movie_reviews.sents(i)\n",
    "    neg_sents_list.append([ \" \".join(sent) for sent in neg_rev_sents]    )\n",
    "\n",
    "for i in movie_reviews.fileids('pos')[0:5]:\n",
    "    \n",
    "    pos_rev_sents = movie_reviews.sents(i)\n",
    "    pos_sents_list.append([ \" \".join(sent) for sent in pos_rev_sents]    )\n",
    "\n",
    "neg_pos_sent = neg_sents_list + pos_sents_list\n",
    "\n",
    "for sublist in neg_pos_sent:\n",
    "    for item in sublist:\n",
    "        all_sents_list.append(item)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sents_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Vectorize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, \n",
    "                             min_df=2, \n",
    "                             stop_words='english',   \n",
    "                             use_idf=True,\n",
    "                             norm=u'l2', \n",
    "                             smooth_idf=True \n",
    "                            )\n",
    "\n",
    "all_sents_tfidf = vectorizer.fit_transform(all_sents_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 538)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sents_tfidf.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<305x538 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1722 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sents_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "161\n"
     ]
    }
   ],
   "source": [
    "neg_cnt = 0\n",
    "for sublist in neg_sents_list:\n",
    "    for item in sublist:\n",
    "        neg_cnt += 1\n",
    "print(neg_cnt)   \n",
    "pos_cnt = 0\n",
    "for sublist in pos_sents_list:\n",
    "    for item in sublist:\n",
    "        pos_cnt += 1\n",
    "print(pos_cnt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Specify model inputs for each feature set\n",
    "\n",
    "# BoW\n",
    "X_bow = reviews.drop(['text_sentence', 'text_source'], 1)\n",
    "Y_bow = reviews['text_source']\n",
    "\n",
    "# Tfidf\n",
    "X_tfidf = all_sents_tfidf\n",
    "Y_tfidf = ['Negative'] * neg_cnt + ['Positive'] * pos_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#splitting into training and test sets\n",
    "X_train_tfidf, X_test_tfidf,y_train_tfidf, y_test_tfidf= train_test_split(X_tfidf,Y_tfidf, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#Reshapes the vectorizer output into something people can read\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
    "#number of sentences\n",
    "n = X_train_tfidf_csr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_bow, X_test_bow,y_train_bow, y_test_bow= train_test_split(X_bow,Y_bow, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(244, 538)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61, 538)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "BoW : \n",
      "  [ 0.6875      0.59574468  0.82978723  0.72340426  0.68085106]\n",
      "Training Data Avg Score: 0.703457446809\n",
      "Test Data Avg Score: 0.628904428904\n",
      "\n",
      "Tfidf : \n",
      " [ 0.82        0.68        0.70833333  0.60416667  0.6875    ]\n",
      "Training Data Avg Score: 0.7\n",
      "Test Data Avg Score: 0.618065268065\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "print('Logistic Regression')\n",
    "# BoW\n",
    "lr = LogisticRegression()\n",
    "lr_bow = lr.fit(X_train_bow, y_train_bow)\n",
    "print('BoW : \\n ', cross_val_score(lr_bow, X_train_bow, y_train_bow, cv=5))\n",
    "print('Training Data Avg Score:', np.mean(cross_val_score(lr_bow, X_train_bow, y_train_bow, cv=5)))\n",
    "print('Test Data Avg Score:', np.mean(cross_val_score(lr_bow, X_test_bow, y_test_bow, cv=5)))\n",
    "\n",
    "# Tfidf\n",
    "lr = LogisticRegression()\n",
    "lr_tfidf = lr.fit(X_train_tfidf, y_train_tfidf)\n",
    "print('\\nTfidf : \\n', cross_val_score(lr_tfidf, X_train_tfidf, y_train_tfidf, cv=5))\n",
    "print('Training Data Avg Score:', np.mean(cross_val_score(lr_tfidf, X_train_tfidf, y_train_tfidf, cv=5)))\n",
    "print('Test Data Avg Score:', np.mean(cross_val_score(lr_tfidf, X_test_tfidf, y_test_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "BoW : \n",
      "  [ 0.54166667  0.68085106  0.57446809  0.59574468  0.68085106]\n",
      "Training Data Avg Score: 0.703280141844\n",
      "Test Data Avg Score: 0.669813519814\n",
      "\n",
      "Tfidf : \n",
      " [ 0.66        0.72        0.625       0.58333333  0.70833333]\n",
      "Training Data Avg Score: 0.7005\n",
      "Test Data Avg Score: 0.570396270396\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "\n",
    "print('Random Forest Classifier')\n",
    "# BoW\n",
    "\n",
    "rfc_bow = rfc.fit(X_train_bow, y_train_bow)\n",
    "print('BoW : \\n ', cross_val_score(rfc_bow, X_train_bow, y_train_bow, cv=5))\n",
    "print('Training Data Avg Score:', np.mean(cross_val_score(rfc_bow, X_train_bow, y_train_bow, cv=5)))\n",
    "print('Test Data Avg Score:', np.mean(cross_val_score(rfc_bow, X_test_bow, y_test_bow, cv=5)))\n",
    "\n",
    "# Tfidf\n",
    "\n",
    "rfc_tfidf = rfc.fit(X_train_tfidf, y_train_tfidf)\n",
    "print('\\nTfidf : \\n', cross_val_score(rfc_tfidf, X_train_tfidf, y_train_tfidf, cv=5))\n",
    "print('Training Data Avg Score:', np.mean(cross_val_score(rfc_tfidf, X_train_tfidf, y_train_tfidf, cv=5)))\n",
    "print('Test Data Avg Score:', np.mean(cross_val_score(rfc_tfidf, X_test_tfidf, y_test_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier\n",
      "BoW : \n",
      "  [ 0.70833333  0.68085106  0.80851064  0.65957447  0.68085106]\n",
      "Training Data Avg Score: 0.711879432624\n",
      "Test Data Avg Score: 0.595337995338\n",
      "\n",
      "Tfidf : \n",
      " [ 0.76        0.62        0.625       0.64583333  0.70833333]\n",
      "Training Data Avg Score: 0.659333333333\n",
      "Test Data Avg Score: 0.52296037296\n"
     ]
    }
   ],
   "source": [
    "gbc = ensemble.GradientBoostingClassifier()\n",
    "print('Gradient Boosting Classifier')\n",
    "# BoW\n",
    "\n",
    "gbc_bow = gbc.fit(X_train_bow, y_train_bow)\n",
    "print('BoW : \\n ', cross_val_score(gbc_bow, X_train_bow, y_train_bow, cv=5))\n",
    "print('Training Data Avg Score:', np.mean(cross_val_score(gbc_bow, X_train_bow, y_train_bow, cv=5)))\n",
    "print('Test Data Avg Score:', np.mean(cross_val_score(gbc_bow, X_test_bow, y_test_bow, cv=5)))\n",
    "\n",
    "# Tfidf\n",
    "\n",
    "gbc_tfidf = gbc.fit(X_train_tfidf, y_train_tfidf)\n",
    "print('\\nTfidf : \\n', cross_val_score(gbc_tfidf, X_train_tfidf, y_train_tfidf, cv=5))\n",
    "print('Training Data Avg Score:', np.mean(cross_val_score(gbc_tfidf, X_train_tfidf, y_train_tfidf, cv=5)))\n",
    "print('Test Data Avg Score:', np.mean(cross_val_score(gbc_tfidf, X_test_tfidf, y_test_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# try to increase accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allwords count 2716\n",
      "allwords count 3511\n"
     ]
    }
   ],
   "source": [
    "# Get bags \n",
    "neg_words = bag_of_words(neg_rev_doc, 2500)\n",
    "\n",
    "pos_words = bag_of_words(pos_rev_doc, 2500)\n",
    "\n",
    "# Combine bags to create common set of unique words\n",
    "common_words = set(neg_words + pos_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dig</th>\n",
       "      <th>against</th>\n",
       "      <th>indiglo</th>\n",
       "      <th>ark</th>\n",
       "      <th>ditzy</th>\n",
       "      <th>infamous</th>\n",
       "      <th>recycle</th>\n",
       "      <th>academy</th>\n",
       "      <th>bar</th>\n",
       "      <th>duddy</th>\n",
       "      <th>...</th>\n",
       "      <th>category</th>\n",
       "      <th>balki</th>\n",
       "      <th>center</th>\n",
       "      <th>000</th>\n",
       "      <th>spending</th>\n",
       "      <th>modern</th>\n",
       "      <th>call</th>\n",
       "      <th>thing</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(plot, :, two, teen, couples, go, to, a, churc...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(they, get, into, an, accident, .)</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(one, of, the, guys, dies, ,, but, his, girlfr...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(what, 's, the, deal, ?)</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(watch, the, movie, and, \", sorta, \")</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1721 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  dig against indiglo ark ditzy infamous recycle academy bar duddy  \\\n",
       "0   0       0       0   0     0        0       0       0   0     0   \n",
       "1   0       0       0   0     0        0       0       0   0     0   \n",
       "2   0       0       0   0     0        0       0       0   0     0   \n",
       "3   0       0       0   0     0        0       0       0   0     0   \n",
       "4   0       0       0   0     0        0       0       0   0     0   \n",
       "\n",
       "      ...     category balki center 000 spending modern call thing  \\\n",
       "0     ...            0     0      0   0        0      0    0     0   \n",
       "1     ...            0     0      0   0        0      0    0     0   \n",
       "2     ...            0     0      0   0        0      0    0     0   \n",
       "3     ...            0     0      0   0        0      0    0     0   \n",
       "4     ...            0     0      0   0        0      0    0     0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (plot, :, two, teen, couples, go, to, a, churc...    Negative  \n",
       "1                 (they, get, into, an, accident, .)    Negative  \n",
       "2  (one, of, the, guys, dies, ,, but, his, girlfr...    Negative  \n",
       "3                           (what, 's, the, deal, ?)    Negative  \n",
       "4              (watch, the, movie, and, \", sorta, \")    Negative  \n",
       "\n",
       "[5 rows x 1721 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create bow features \n",
    "reviews = bow_features(sentences_df, common_words)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entityty_types(df):\n",
    "    \n",
    "    person_ent_type = []\n",
    "    qty_ent_type = []\n",
    "    ordinal_ent_type = []\n",
    "    time_ent_type = []\n",
    "    org_ent_type = []\n",
    "    lang_ent_type = []\n",
    "    date_ent_type = []\n",
    "    card_ent_type = []\n",
    "    gpe_ent_type = []\n",
    "    fac_ent_type = []\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        person_count = 0\n",
    "        qty_count= 0\n",
    "        ordinal_count = 0\n",
    "        time_count = 0\n",
    "        org_count = 0\n",
    "        lang_count = 0\n",
    "        date_count= 0\n",
    "        cardinal_count =0 \n",
    "        gpe_count= 0\n",
    "        fac_count = 0\n",
    "    \n",
    "        for token in sentence:\n",
    "            if token.ent_type_ == 'PERSON':\n",
    "                person_count += 1\n",
    "        \n",
    "            if token.ent_type_ == 'QUANTITY':\n",
    "                qty_count += 1\n",
    "            \n",
    "            if token.ent_type_ == 'ORDINAL':\n",
    "                ordinal_count += 1\n",
    "            \n",
    "            if token.ent_type_ == 'TIME':\n",
    "                time_count += 1\n",
    "            \n",
    "            if token.ent_type_ == 'ORG':\n",
    "                org_count += 1\n",
    "            \n",
    "            if token.ent_type_ == 'LANGUAGE':\n",
    "                lang_count += 1\n",
    "            if token.ent_type_ == 'DATE':\n",
    "                date_count += 1            \n",
    "        \n",
    "            if token.ent_type_ == 'CARDINAL':\n",
    "                cardinal_count += 1            \n",
    "            if token.ent_type_ == 'GPE':\n",
    "                gpe_count += 1            \n",
    "            if token.ent_type_ == 'FAC':\n",
    "                fac_count += 1            \n",
    "            \n",
    "        person_ent_type.append(person_count)\n",
    "        qty_ent_type.append(qty_count)\n",
    "        ordinal_ent_type.append(ordinal_count)\n",
    "        time_ent_type.append(time_count)\n",
    "        org_ent_type.append(org_count)\n",
    "        lang_ent_type.append(lang_count)\n",
    "        date_ent_type.append(date_count)\n",
    "        card_ent_type.append(cardinal_count)\n",
    "        gpe_ent_type.append(gpe_count)\n",
    "        fac_ent_type.append(fac_count)\n",
    "\n",
    "          \n",
    "    df['person_ent'] = person_ent_type\n",
    "    df['qty_ent'] = qty_ent_type\n",
    "    df['ordinal_ent'] = ordinal_ent_type\n",
    "    df['time_ent'] = time_ent_type\n",
    "    df['org_ent'] = org_ent_type\n",
    "    df['lang_ent'] = lang_ent_type\n",
    "    df['date_ent'] = date_ent_type\n",
    "    df['card_ent'] = card_ent_type\n",
    "    df['gpe_ent'] = gpe_ent_type\n",
    "    df['fac_ent'] = fac_ent_type\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = entityty_types(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dig</th>\n",
       "      <th>against</th>\n",
       "      <th>indiglo</th>\n",
       "      <th>ark</th>\n",
       "      <th>ditzy</th>\n",
       "      <th>infamous</th>\n",
       "      <th>recycle</th>\n",
       "      <th>academy</th>\n",
       "      <th>bar</th>\n",
       "      <th>duddy</th>\n",
       "      <th>...</th>\n",
       "      <th>person_ent</th>\n",
       "      <th>qty_ent</th>\n",
       "      <th>ordinal_ent</th>\n",
       "      <th>time_ent</th>\n",
       "      <th>org_ent</th>\n",
       "      <th>lang_ent</th>\n",
       "      <th>date_ent</th>\n",
       "      <th>card_ent</th>\n",
       "      <th>gpe_ent</th>\n",
       "      <th>fac_ent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1731 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  dig against indiglo ark ditzy infamous recycle academy bar duddy   ...    \\\n",
       "0   0       0       0   0     0        0       0       0   0     0   ...     \n",
       "1   0       0       0   0     0        0       0       0   0     0   ...     \n",
       "2   0       0       0   0     0        0       0       0   0     0   ...     \n",
       "3   0       0       0   0     0        0       0       0   0     0   ...     \n",
       "4   0       0       0   0     0        0       0       0   0     0   ...     \n",
       "\n",
       "  person_ent qty_ent ordinal_ent time_ent org_ent lang_ent date_ent card_ent  \\\n",
       "0          0       0           0        0       0        0        0        1   \n",
       "1          0       0           0        0       0        0        0        0   \n",
       "2          0       0           0        0       0        0        0        1   \n",
       "3          0       0           0        0       0        0        0        0   \n",
       "4          0       0           0        0       0        0        0        0   \n",
       "\n",
       "  gpe_ent fac_ent  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "2       0       0  \n",
       "3       0       0  \n",
       "4       0       0  \n",
       "\n",
       "[5 rows x 1731 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_bow = reviews.drop(['text_sentence', 'text_source'], 1)\n",
    "Y_bow = reviews['text_source']\n",
    "X_train_bow, X_test_bow,y_train_bow, y_test_bow= train_test_split(X_bow,Y_bow, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "BoW : \n",
      "  [ 0.66666667  0.61702128  0.85106383  0.70212766  0.70212766]\n",
      "Training Data Avg Score: 0.70780141844\n",
      "Test Data Avg Score: 0.697086247086\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "print('Logistic Regression')\n",
    "# BoW\n",
    "lr = LogisticRegression()\n",
    "lr_bow = lr.fit(X_train_bow, y_train_bow)\n",
    "print('BoW : \\n ', cross_val_score(lr_bow, X_train_bow, y_train_bow, cv=5))\n",
    "print('Training Data Avg Score:', np.mean(cross_val_score(lr_bow, X_train_bow, y_train_bow, cv=5)))\n",
    "print('Test Data Avg Score:', np.mean(cross_val_score(lr_bow, X_test_bow, y_test_bow, cv=5)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter  {'C': 10, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "parameters =[ {'C': [0.01, 0.1, 1, 10, 100],'solver':['liblinear'],'penalty':['l1', 'l2'],'fit_intercept':[True]},\n",
    "            {'C': [0.01, 0.1, 1, 10, 100],'solver':['lbfgs','newton-cg'],'fit_intercept':[True]}\n",
    "            ]\n",
    "\n",
    "gr_logr = GridSearchCV(lr,param_grid = parameters )\n",
    "gr_logr.fit(X_train_bow, y_train_bow)\n",
    "print('Best Parameter ', gr_logr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW : \n",
      "  [ 0.66666667  0.61702128  0.85106383  0.70212766  0.70212766]\n",
      "Training Data Avg Score: 0.70780141844\n",
      "Test Data Avg Score: 0.697086247086\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(**gr_logr.best_params_, random_state = 10)\n",
    "lr.fit(X_train_bow, y_train_bow)\n",
    "print('BoW : \\n ', cross_val_score(lr_bow, X_train_bow, y_train_bow, cv=5))\n",
    "print('Training Data Avg Score:', np.mean(cross_val_score(lr_bow, X_train_bow, y_train_bow, cv=5)))\n",
    "print('Test Data Avg Score:', np.mean(cross_val_score(lr_bow, X_test_bow, y_test_bow, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Though the training data score remained same, the test data score increased from 63 % to 70% ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "BoW : \n",
      "  [ 0.64583333  0.59574468  0.59574468  0.55319149  0.65957447]\n",
      "Training Data Avg Score: 0.635372340426\n",
      "Test Data Avg Score: 0.627389277389\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Classifier')\n",
    "# BoW\n",
    "\n",
    "rfc_bow = rfc.fit(X_train_bow, y_train_bow)\n",
    "print('BoW : \\n ', cross_val_score(rfc_bow, X_train_bow, y_train_bow, cv=5))\n",
    "print('Training Data Avg Score:', np.mean(cross_val_score(rfc_bow, X_train_bow, y_train_bow, cv=5)))\n",
    "print('Test Data Avg Score:', np.mean(cross_val_score(rfc_bow, X_test_bow, y_test_bow, cv=5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.690677966102\n",
      "{'max_depth': None, 'max_features': 'log2', 'min_samples_split': 8, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "rfc_params  = {\n",
    "    'n_estimators':[100,200,500],\n",
    "    'max_features':['auto', 'sqrt', 'log2'],\n",
    "    'max_depth':[4, 6,7, 8, None],\n",
    "    'min_samples_split':[2, 8]\n",
    "}\n",
    "rfc_grid = GridSearchCV(ensemble.RandomForestClassifier(random_state=10), param_grid=rfc_params)\n",
    "rfc_grid.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "print(rfc_grid.best_score_)\n",
    "print(rfc_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "BoW : \n",
      "  [ 0.60416667  0.68085106  0.68085106  0.74468085  0.63829787]\n",
      "Training Data Avg Score: 0.712056737589\n",
      "Test Data Avg Score: 0.697086247086\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Classifier')\n",
    "# BoW\n",
    "rfc = ensemble.RandomForestClassifier(**rfc_grid.best_params_)\n",
    "rfc_bow = rfc.fit(X_train_bow, y_train_bow)\n",
    "print('BoW : \\n ', cross_val_score(rfc_bow, X_train_bow, y_train_bow, cv=5))\n",
    "print('Training Data Avg Score:', np.mean(cross_val_score(rfc_bow, X_train_bow, y_train_bow, cv=5)))\n",
    "print('Test Data Avg Score:', np.mean(cross_val_score(rfc_bow, X_test_bow, y_test_bow, cv=5)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we got 3% increase in the test data score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "BoW : \n",
      "  [ 0.64583333  0.65957447  0.70212766  0.72340426  0.72340426]\n",
      "Training Data Avg Score: 0.678102836879\n",
      "Test Data Avg Score: 0.647086247086\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Classifier')\n",
    "# BoW\n",
    "rfc = ensemble.RandomForestClassifier(**rfc_grid.best_params_)\n",
    "rfc_bow = rfc.fit(X_train_bow, y_train_bow)\n",
    "print('BoW : \\n ', cross_val_score(rfc_bow, X_train_bow, y_train_bow, cv=5))\n",
    "print('Training Data Avg Score:', np.mean(cross_val_score(rfc_bow, X_train_bow, y_train_bow, cv=5)))\n",
    "print('Test Data Avg Score:', np.mean(cross_val_score(rfc_bow, X_test_bow, y_test_bow, cv=5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier\n",
      "BoW : \n",
      "  [ 0.66666667  0.70212766  0.80851064  0.70212766  0.59574468]\n",
      "Training Data Avg Score: 0.690780141844\n",
      "Test Data Avg Score: 0.612004662005\n"
     ]
    }
   ],
   "source": [
    "gbc = ensemble.GradientBoostingClassifier()\n",
    "print('Gradient Boosting Classifier')\n",
    "# BoW\n",
    "\n",
    "gbc_bow = gbc.fit(X_train_bow, y_train_bow)\n",
    "print('BoW : \\n ', cross_val_score(gbc_bow, X_train_bow, y_train_bow, cv=5))\n",
    "print('Training Data Avg Score:', np.mean(cross_val_score(gbc_bow, X_train_bow, y_train_bow, cv=5)))\n",
    "print('Test Data Avg Score:', np.mean(cross_val_score(gbc_bow, X_test_bow, y_test_bow, cv=5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters {'learning_rate': 0.3, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 300, 'subsample': 1} \n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_test1 = {'n_estimators':[100,200,300,500],\n",
    "               'learning_rate': [0.03, 0.1, 0.3],\n",
    "               'max_depth':[2,4,None],               \n",
    "               'loss': ['deviance'],\n",
    "               'subsample':[0.8,0.5, 1]              \n",
    "              }\n",
    " \n",
    "\n",
    "gsearch1 = GridSearchCV(\n",
    "    estimator = ensemble.GradientBoostingClassifier(random_state=10), \n",
    "    param_grid = param_test1)\n",
    "gsearch1.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "print('\\nBest parameters {} '.format(gsearch1.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier\n",
      "BoW : \n",
      "  [ 0.64583333  0.68085106  0.80851064  0.68085106  0.65957447]\n",
      "Training Data Avg Score: 0.703723404255\n",
      "Test Data Avg Score: 0.626107226107\n"
     ]
    }
   ],
   "source": [
    "gbc = ensemble.GradientBoostingClassifier(**gsearch1.best_params_)\n",
    "print('Gradient Boosting Classifier')\n",
    "# BoW\n",
    "\n",
    "gbc_bow = gbc.fit(X_train_bow, y_train_bow)\n",
    "print('BoW : \\n ', cross_val_score(gbc_bow, X_train_bow, y_train_bow, cv=5))\n",
    "print('Training Data Avg Score:', np.mean(cross_val_score(gbc_bow, X_train_bow, y_train_bow, cv=5)))\n",
    "print('Test Data Avg Score:', np.mean(cross_val_score(gbc_bow, X_test_bow, y_test_bow, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see 4% improvement here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "The bag of words model performed better than the tfidf model.\n",
    "For bag of words model, when using Logistic Regression, the training data score remained same but the test data score increased from 63 % to 70% . So here we saw a 7%  increase in the accuracy, where as for Gradient Boosting Classifier, we saw 4% improvement and for Random Forest Classifier, we got 3% increase in the test data score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
