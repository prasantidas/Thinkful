{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import gutenberg, stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to clean text.\n",
    "def text_cleaner(text):\n",
    "    \n",
    "    # Visual inspection shows spaCy does not recognize the double dash '--'.\n",
    "    # Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    \n",
    "    # Get rid of headings in square brackets.\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    \n",
    "    # Get rid of chapter titles.\n",
    "    text = re.sub(r'Chapter \\d+','',text)\n",
    "    \n",
    "    # Get rid of extra whitespace.\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import all the Austen in the Project Gutenberg corpus.\n",
    "\n",
    "sense = gutenberg.raw('austen-sense.txt')\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "emma = gutenberg.raw('austen-emma.txt')\n",
    "\n",
    "\n",
    "# Clean the data.\n",
    "sense_clean = text_cleaner(sense)\n",
    "persuasion_clean = text_cleaner(persuasion)\n",
    "\n",
    "emma_clean = text_cleaner(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666583\n",
      "462818\n",
      "876869\n"
     ]
    }
   ],
   "source": [
    "print(len(sense_clean))\n",
    "print(len(persuasion_clean))\n",
    "print(len(emma_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n",
      "366583\n",
      "200000\n",
      "262818\n",
      "300000\n",
      "300000\n",
      "276869\n"
     ]
    }
   ],
   "source": [
    "sense_1 = sense_clean[0:300000]\n",
    "sense_2 = sense_clean[300000:]\n",
    "\n",
    "persuasion_1 = persuasion_clean[0:200000]\n",
    "persuasion_2 = persuasion_clean[200000:]\n",
    "\n",
    "emma_1 = emma_clean[0:300000]\n",
    "emma_2 = emma_clean[300000:600000]\n",
    "emma_3 = emma_clean[600000:]\n",
    "\n",
    "print(len(sense_1))\n",
    "print(len(sense_2))\n",
    "\n",
    "print(len(persuasion_1))\n",
    "print(len(persuasion_2))\n",
    "\n",
    "print(len(emma_1))\n",
    "print(len(emma_2))\n",
    "print(len(emma_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sense_1_doc = nlp(sense_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sense_2_doc = nlp(sense_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "persuasion_1_doc = nlp(persuasion_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "persuasion_2_doc = nlp(persuasion_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emma_1_doc = nlp(emma_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emma_2_doc = nlp(emma_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emma_3_doc = nlp(emma_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_sentences = []\n",
    "for sentence in sense_1_doc.sents:\n",
    "    sentence = [\n",
    "        token.lemma_.lower()\n",
    "        for token in sentence\n",
    "        if not token.is_stop\n",
    "        and not token.is_punct\n",
    "    ]\n",
    "    all_sentences.append(sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for sentence in sense_2_doc.sents:\n",
    "    sentence2 = [\n",
    "        token.lemma_.lower()\n",
    "        for token in sentence\n",
    "        if not token.is_stop\n",
    "        and not token.is_punct\n",
    "    ]\n",
    "    all_sentences.append(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for sentence in persuasion_1_doc.sents:\n",
    "    sentence3 = [\n",
    "        token.lemma_.lower()\n",
    "        for token in sentence\n",
    "        if not token.is_stop\n",
    "        and not token.is_punct\n",
    "    ]\n",
    "    all_sentences.append(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for sentence in persuasion_2_doc.sents:\n",
    "    sentence4 = [\n",
    "        token.lemma_.lower()\n",
    "        for token in sentence\n",
    "        if not token.is_stop\n",
    "        and not token.is_punct\n",
    "    ]\n",
    "    all_sentences.append(sentence4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for sentence in emma_1_doc.sents:\n",
    "    sentence5 = [\n",
    "        token.lemma_.lower()\n",
    "        for token in sentence\n",
    "        if not token.is_stop\n",
    "        and not token.is_punct\n",
    "    ]\n",
    "    all_sentences.append(sentence5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for sentence in emma_2_doc.sents:\n",
    "    sentence6 = [\n",
    "        token.lemma_.lower()\n",
    "        for token in sentence\n",
    "        if not token.is_stop\n",
    "        and not token.is_punct\n",
    "    ]\n",
    "    all_sentences.append(sentence6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for sentence in emma_3_doc.sents:\n",
    "    sentence7 = [\n",
    "        token.lemma_.lower()\n",
    "        for token in sentence\n",
    "        if not token.is_stop\n",
    "        and not token.is_punct\n",
    "    ]\n",
    "    all_sentences.append(sentence7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-pron-', 'survive', '-pron-', 'uncle', 'no', 'longer', 'and', 'ten', 'thousand', 'pound', 'include', 'the', 'late', 'legacy', 'be', 'all', 'that', 'remain', 'for', '-pron-', 'widow', 'and', 'daughter']\n",
      "We have 18161 sentences and 2006270 tokens.\n"
     ]
    }
   ],
   "source": [
    "print(all_sentences[20])\n",
    "print('We have {} sentences and {} tokens.'.format(len(all_sentences), (len(sense_clean) + len(persuasion_clean) + len(emma_clean))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gyans\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# conda install -c anaconda gensim\n",
    "import gensim\n",
    "from gensim.models import word2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = word2vec.Word2Vec(\n",
    "    all_sentences,\n",
    "    workers=2,     # Number of threads to run in parallel (if your computer does parallel processing).\n",
    "    min_count=10,  # Minimum word count threshold.\n",
    "    window=6,      # Number of words around target word to consider.\n",
    "    sg=0,          # Use CBOW because our corpus is small.\n",
    "    sample=1e-3 ,  # Penalize frequent words.\n",
    "    size=300,      # Word vector length.\n",
    "    hs=1           # Use hierarchical softmax.\n",
    ")\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('people', 0.542380690574646), ('child', 0.5123438835144043), ('wait', 0.49683427810668945), ('person', 0.48106372356414795), ('lay', 0.4491744339466095), ('daughter', 0.44877469539642334), ('sake', 0.44300079345703125), ('invite', 0.4413103461265564), ('chamber', 0.440081924200058), ('set', 0.43497589230537415)]\n",
      "0.560183042806\n",
      "0.275718331033\n",
      "marriage\n"
     ]
    }
   ],
   "source": [
    "# List of words in model.\n",
    "vocab = model.wv.vocab.keys()\n",
    "\n",
    "print(model.wv.most_similar(positive=['lady', 'man'], negative=['woman']))\n",
    "\n",
    "# Similarity is calculated using the cosine, so again 1 is total\n",
    "# similarity and 0 is no similarity.\n",
    "print(model.wv.similarity('loud', 'aloud'))\n",
    "print(model.wv.similarity('mr', 'mrs'))\n",
    "\n",
    "# One of these things is not like the other...\n",
    "print(model.wv.doesnt_match(\"breakfast marriage dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Drill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n",
      "[('famous', 0.5893282890319824), ('people', 0.5829415321350098), ('person', 0.5615419149398804), ('gilberts', 0.5614441633224487), ('cape', 0.544938325881958), ('straightforward', 0.5141352415084839), ('clownish', 0.5114244222640991), ('physician', 0.5096943378448486), ('address', 0.5021142959594727), ('kellynch', 0.49815690517425537)]\n",
      "0.609513507993\n",
      "0.574171428229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gyans\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marriage\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(\n",
    "    all_sentences,\n",
    "    workers=2,     # Number of threads to run in parallel (if your computer does parallel processing).\n",
    "    min_count=2,  # Minimum word count threshold.\n",
    "    window=3,      # Number of words around target word to consider.\n",
    "    sg=0,          # Use CBOW because our corpus is small.\n",
    "    sample=1e-3 ,  # Penalize frequent words.\n",
    "    size=300,      # Word vector length.\n",
    "    hs=1           # Use hierarchical softmax.\n",
    ")\n",
    "\n",
    "print('done!')\n",
    "\n",
    "# List of words in model.\n",
    "vocab = model.wv.vocab.keys()\n",
    "\n",
    "print(model.wv.most_similar(positive=['lady', 'man'], negative=['woman']))\n",
    "\n",
    "# Similarity is calculated using the cosine, so again 1 is total\n",
    "# similarity and 0 is no similarity.\n",
    "print(model.wv.similarity('loud', 'aloud'))\n",
    "print(model.wv.similarity('mr', 'mrs'))\n",
    "\n",
    "# One of these things is not like the other...\n",
    "print(model.doesnt_match(\"breakfast marriage dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n",
      "[('grandson', 0.7622113227844238), ('iv', 0.758206844329834), ('middleton', 0.7399743795394897), ('henry', 0.7323991060256958), ('patronage', 0.7281194925308228), ('brown', 0.7158392667770386), ('richard', 0.7148146629333496), ('bella', 0.7125517129898071), ('abruptness', 0.7116174697875977), ('pointer', 0.710627555847168)]\n",
      "0.954916424423\n",
      "0.945722839831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gyans\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marriage\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(\n",
    "    all_sentences,\n",
    "    workers=2,     # Number of threads to run in parallel (if your computer does parallel processing).\n",
    "    min_count=2,  # Minimum word count threshold.\n",
    "    window=3,      # Number of words around target word to consider.\n",
    "    sg=0,          # Use CBOW because our corpus is small.\n",
    "    sample=1e-3 ,  # Penalize frequent words.\n",
    "    size=300,      # Word vector length.\n",
    "    hs=0           # Use hierarchical softmax.\n",
    ")\n",
    "\n",
    "print('done!')\n",
    "\n",
    "# List of words in model.\n",
    "vocab = model.wv.vocab.keys()\n",
    "\n",
    "print(model.wv.most_similar(positive=['lady', 'man'], negative=['woman']))\n",
    "\n",
    "# Similarity is calculated using the cosine, so again 1 is total\n",
    "# similarity and 0 is no similarity.\n",
    "print(model.wv.similarity('loud', 'aloud'))\n",
    "print(model.wv.similarity('mr', 'mrs'))\n",
    "\n",
    "# One of these things is not like the other...\n",
    "print(model.doesnt_match(\"breakfast marriage dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n",
      "[('person', 0.5112453699111938), ('physician', 0.5019273161888123), ('people', 0.4616897404193878), ('gilberts', 0.46049851179122925), ('offence', 0.44991835951805115), ('party', 0.44036799669265747), ('crime', 0.44010987877845764), ('gentleman', 0.43712136149406433), ('subject', 0.4238295555114746), ('negotiation', 0.4132401645183563)]\n",
      "0.276240473093\n",
      "0.543629915672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gyans\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marriage\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(\n",
    "    all_sentences,\n",
    "    workers=2,     # Number of threads to run in parallel (if your computer does parallel processing).\n",
    "    min_count=2,  # Minimum word count threshold.\n",
    "    window=3,      # Number of words around target word to consider.\n",
    "    sg=0,          # Use CBOW because our corpus is small.\n",
    "    sample=1e-1 ,  # Penalize frequent words.\n",
    "    size=300,      # Word vector length.\n",
    "    hs=1           # Use hierarchical softmax.\n",
    ")\n",
    "\n",
    "print('done!')\n",
    "\n",
    "# List of words in model.\n",
    "vocab = model.wv.vocab.keys()\n",
    "\n",
    "print(model.wv.most_similar(positive=['lady', 'man'], negative=['woman']))\n",
    "\n",
    "# Similarity is calculated using the cosine, so again 1 is total\n",
    "# similarity and 0 is no similarity.\n",
    "print(model.wv.similarity('loud', 'aloud'))\n",
    "print(model.wv.similarity('mr', 'mrs'))\n",
    "\n",
    "# One of these things is not like the other...\n",
    "print(model.doesnt_match(\"breakfast marriage dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "With changes in the hyperparameters of this model, finding the odd one out has performed consistently accurate than others.\n",
    "We got result as \"marriage\" which is dissimilar to \"breakfast\", \"lunch\", and \"dinner\". \n",
    "For analogy while some words given above might possibly fill in the analogy lady:woman::man:?, most answers likely make little sense. \n",
    "\n",
    "Larger windows tend to capture more topic/domain information, while Smaller windows tend to capture more about word itself. So When decreased the window size from 6 to 3 and changed Minimum word count threshold from 10 to 2 , we got 4% improvement for finding similiarity between word \"loud\" and \"aloud\". But this incraesed the score from 27% to 57% for finding similarity between 'mr' and 'mrs'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drill 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Google's pre-trained Word2Vec model.\n",
    "#model = gensim.models.KeyedVectors.load_word2vec_format('./model/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# Ran into memory problems - used the web interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Analogies:\n",
    "\n",
    "cat  is to kitten as dog is to ? Ans was puppy \n",
    "[[\"puppy\",0.769972562789917],[\"pup\",0.6861710548400879],[\"pit_bull\",0.6776559352874756],[\"dogs\",0.6770986318588257],[\"Rottweiler\",0.66466224193573]]\n",
    "\n",
    "\n",
    "day is to night as black is to ? Ans was white\n",
    "\n",
    " [[\"white\",0.5813108682632446],[\"Responded_Letterman_How\",0.4426087737083435],[\"raspberries_inhibited\",0.4368473291397095],[\"Shilah_Phillips\",0.42732203006744385],[\"sang_Learnin\",0.4253648519515991]]\n",
    "\n",
    "day is to sun as night is to ?\n",
    "ans  [[\"Robert_Tychkowski_Edmonton\",0.5355181694030762],[\"CARA_EASTWOOD\",0.5136322975158691],[\"STEPHAN_FRAZIER\",0.5134779214859009],[\"hijacked_airliner_belongs\",0.5006062984466553],[\"columnist_Bill_Zwecker\",0.5005240440368652]]\n",
    "\n",
    "    \n",
    "# Closest words:\n",
    "\n",
    "bread \n",
    "[[\"butter\",0.6417260766029358],[\"rye_sourdough\",0.6290417909622192],[\"breads\",0.6243128776550293],[\"loaf\",0.6184971332550049],[\"flour\",0.6152125597000122]]\n",
    "\n",
    "rain\n",
    " [[\"heavy_rain\",0.8421464562416077],[\"downpour\",0.7967616319656372],[\"rains\",0.7827130556106567],[\"torrential_rain\",0.7578904628753662],[\"Rain\",0.7476006746292114]]\n",
    "    \n",
    "\n",
    "\n",
    "# Words does not fit-\n",
    "apple orange strawberry egg\n",
    "-- output was egg\n",
    "blue red green photo\n",
    "-- output was photo\n",
    "\n",
    "pen paper ink ball\n",
    "-- ouput was ball"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the model is very good at finding phrase that doesnot fit, and also pretty good at finding reasonable similarities. but struggles with finding analogies. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
