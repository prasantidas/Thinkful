{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "# Load and clean the data.\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "# The Chapter indicator is idiosyncratic\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)\n",
    "    \n",
    "alice = text_cleaner(alice)\n",
    "persuasion = text_cleaner(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse the cleaned novels. This can take a bit.\n",
    "alice_doc = nlp(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "persuasion_doc = nlp(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
       "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
       "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
       "3                                      (Oh, dear, !)  Carroll\n",
       "4                         (I, shall, be, late, !, ')  Carroll"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents)\n",
    "sentences.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(alice_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n",
      "Processing row 3500\n",
      "Processing row 4000\n",
      "Processing row 4500\n",
      "Processing row 5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>friend</th>\n",
       "      <th>entrance</th>\n",
       "      <th>hop</th>\n",
       "      <th>praise</th>\n",
       "      <th>charming</th>\n",
       "      <th>drawl</th>\n",
       "      <th>amiable</th>\n",
       "      <th>fling</th>\n",
       "      <th>glad</th>\n",
       "      <th>reasonable</th>\n",
       "      <th>...</th>\n",
       "      <th>mouse</th>\n",
       "      <th>six</th>\n",
       "      <th>player</th>\n",
       "      <th>lowing</th>\n",
       "      <th>objection</th>\n",
       "      <th>cutting</th>\n",
       "      <th>poker</th>\n",
       "      <th>seal</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3059 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  friend entrance hop praise charming drawl amiable fling glad reasonable  \\\n",
       "0      0        0   0      0        0     0       0     0    0          0   \n",
       "1      0        0   0      0        0     0       0     0    0          0   \n",
       "2      0        0   0      0        0     0       0     0    0          0   \n",
       "3      0        0   0      0        0     0       0     0    0          0   \n",
       "4      0        0   0      0        0     0       0     0    0          0   \n",
       "\n",
       "      ...     mouse six player lowing objection cutting poker seal  \\\n",
       "0     ...         0   0      0      0         0       0     0    0   \n",
       "1     ...         0   0      0      0         0       0     0    0   \n",
       "2     ...         0   0      0      0         0       0     0    0   \n",
       "3     ...         0   0      0      0         0       0     0    0   \n",
       "4     ...         0   0      0      0         0       0     0    0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (Alice, was, beginning, to, get, very, tired, ...     Carroll  \n",
       "1  (So, she, was, considering, in, her, own, mind...     Carroll  \n",
       "2  (There, was, nothing, so, VERY, remarkable, in...     Carroll  \n",
       "3                                      (Oh, dear, !)     Carroll  \n",
       "4                         (I, shall, be, late, !, ')     Carroll  \n",
       "\n",
       "[5 rows x 3059 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the bags.\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(alicewords + persuasionwords)\n",
    "\n",
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3057\n"
     ]
    }
   ],
   "source": [
    "print(len(common_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.982252141983\n",
      "\n",
      "Test set score: 0.838990825688\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3268, 3057) (3268,)\n",
      "Training set score: 0.948286413709\n",
      "\n",
      "Test set score: 0.884403669725\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.856181150551\n",
      "\n",
      "Test set score: 0.849082568807\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 5000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(5000)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Try adding some common phrases (500 from each author) from the works into our dataframe\n",
    "\n",
    "\n",
    "def text_phrases(text):\n",
    "    noun_phrases = [np.text for np in text.noun_chunks]\n",
    "    return [item[0] for item in Counter(noun_phrases).most_common(500)]\n",
    "\n",
    "\n",
    "# Set up\n",
    "alice_phrases = text_phrases(alice_doc)\n",
    "persuasion_phrases = text_phrases(persuasion_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_phrases = set(alice_phrases + persuasion_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "   \n",
    "    \n",
    "    df = pd.DataFrame(columns= set(list(common_words) + list(common_phrases )))\n",
    "\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    df.loc[:, common_phrases] = 0\n",
    "    df['sent_length'] = 0\n",
    "    \n",
    "    df['prev_sent_length'] = 0\n",
    "    df['next_sent_length'] = 0\n",
    "    df['num_words_repeated_from_prior_sent'] = 0\n",
    "    \n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "          #Check to see if each phrase turns up in the sentence (store as binary var for the time being)\n",
    "        \n",
    "        for phrase in common_phrases:\n",
    "            if phrase in str(sentence):\n",
    "                df.loc[i, phrase] = 1\n",
    "                \n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        #Also add # of repeated words from one sentence to the next\n",
    "        repeats = 0\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "            if i > 0: \n",
    "                if ((df.loc[i-1, word] > 0) & (df.loc[i, word] > 0)):\n",
    "                    repeats += 1\n",
    "            else: \n",
    "                repeats = 0\n",
    "        df['num_words_repeated_from_prior_sent'][i] = repeats        \n",
    "\n",
    "        sent_len = 0    \n",
    "        num_punct = 0 \n",
    "        \n",
    "        for token in sentence:\n",
    "        \n",
    "            if not token.is_punct:\n",
    "                sent_len += 1\n",
    "            else:\n",
    "                num_punct += 1\n",
    "        df.loc[i, 'sent_length'] = sent_len\n",
    "        df.loc[i, 'sent_punct_count'] = num_punct\n",
    "        \n",
    "        if i > 0:\n",
    "            df.loc[i, 'prev_sent_length'] = df.loc[i-1, 'sent_length']\n",
    "        else:\n",
    "            df.loc[i, 'prev_sent_length'] = np.nan\n",
    "                              \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "                      \n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "    #Back out of the loop through sentences and just shift the df by one to get the \"next sent len\" feature\n",
    "    df['next_sent_length'] = df['sent_length'].shift(-1)         \n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the bags.\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(alicewords + persuasionwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gyans\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n",
      "Processing row 3500\n",
      "Processing row 4000\n",
      "Processing row 4500\n",
      "Processing row 5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>friend</th>\n",
       "      <th>praise</th>\n",
       "      <th>tenantry</th>\n",
       "      <th>amiable</th>\n",
       "      <th>dozen</th>\n",
       "      <th>vanity</th>\n",
       "      <th>precept</th>\n",
       "      <th>ground</th>\n",
       "      <th>scene</th>\n",
       "      <th>bitter</th>\n",
       "      <th>...</th>\n",
       "      <th>thorough</th>\n",
       "      <th>player</th>\n",
       "      <th>lowing</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "      <th>sent_length</th>\n",
       "      <th>prev_sent_length</th>\n",
       "      <th>next_sent_length</th>\n",
       "      <th>num_words_repeated_from_prior_sent</th>\n",
       "      <th>sent_punct_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>56</td>\n",
       "      <td>57.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>29</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5845 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  friend praise tenantry amiable dozen vanity precept ground scene bitter  \\\n",
       "0      0      0        0       0     0      0       0      0     0      0   \n",
       "1      0      0        0       0     0      0       0      0     0      0   \n",
       "2      0      0        0       0     0      0       0      0     0      0   \n",
       "3      0      0        0       0     0      0       0      0     0      0   \n",
       "4      0      0        0       0     0      0       0      0     0      0   \n",
       "\n",
       "        ...        thorough player lowing  \\\n",
       "0       ...               0      0      0   \n",
       "1       ...               0      0      0   \n",
       "2       ...               0      0      0   \n",
       "3       ...               0      0      0   \n",
       "4       ...               0      0      0   \n",
       "\n",
       "                                       text_sentence text_source sent_length  \\\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...     Carroll          57   \n",
       "1  (So, she, was, considering, in, her, own, mind...     Carroll          56   \n",
       "2  (There, was, nothing, so, VERY, remarkable, in...     Carroll          29   \n",
       "3                                      (Oh, dear, !)     Carroll           2   \n",
       "4                         (I, shall, be, late, !, ')     Carroll           4   \n",
       "\n",
       "  prev_sent_length next_sent_length num_words_repeated_from_prior_sent  \\\n",
       "0              NaN             56.0                                  0   \n",
       "1             57.0             29.0                                 21   \n",
       "2             56.0              2.0                                 12   \n",
       "3             29.0              4.0                                  2   \n",
       "4              2.0            109.0                                  0   \n",
       "\n",
       "  sent_punct_count  \n",
       "0             10.0  \n",
       "1              7.0  \n",
       "2              4.0  \n",
       "3              1.0  \n",
       "4              2.0  \n",
       "\n",
       "[5 rows x 5845 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = word_counts.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5448, 5845)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entityty_types(df):\n",
    "    \n",
    "    person_ent_type = []\n",
    "    qty_ent_type = []\n",
    "    ordinal_ent_type = []\n",
    "    time_ent_type = []\n",
    "    org_ent_type = []\n",
    "    lang_ent_type = []\n",
    "    date_ent_type = []\n",
    "    card_ent_type = []\n",
    "    gpe_ent_type = []\n",
    "    fac_ent_type = []\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        person_count = 0\n",
    "        qty_count= 0\n",
    "        ordinal_count = 0\n",
    "        time_count = 0\n",
    "        org_count = 0\n",
    "        lang_count = 0\n",
    "        date_count= 0\n",
    "        cardinal_count =0 \n",
    "        gpe_count= 0\n",
    "        fac_count = 0\n",
    "    \n",
    "        for token in sentence:\n",
    "            if token.ent_type_ == 'PERSON':\n",
    "                person_count += 1\n",
    "        \n",
    "            if token.ent_type_ == 'QUANTITY':\n",
    "                qty_count += 1\n",
    "            \n",
    "            if token.ent_type_ == 'ORDINAL':\n",
    "                ordinal_count += 1\n",
    "            \n",
    "            if token.ent_type_ == 'TIME':\n",
    "                time_count += 1\n",
    "            \n",
    "            if token.ent_type_ == 'ORG':\n",
    "                org_count += 1\n",
    "            \n",
    "            if token.ent_type_ == 'LANGUAGE':\n",
    "                lang_count += 1\n",
    "            if token.ent_type_ == 'DATE':\n",
    "                date_count += 1            \n",
    "        \n",
    "            if token.ent_type_ == 'CARDINAL':\n",
    "                cardinal_count += 1            \n",
    "            if token.ent_type_ == 'GPE':\n",
    "                gpe_count += 1            \n",
    "            if token.ent_type_ == 'FAC':\n",
    "                fac_count += 1            \n",
    "            \n",
    "        person_ent_type.append(person_count)\n",
    "        qty_ent_type.append(qty_count)\n",
    "        ordinal_ent_type.append(ordinal_count)\n",
    "        time_ent_type.append(time_count)\n",
    "        org_ent_type.append(org_count)\n",
    "        lang_ent_type.append(lang_count)\n",
    "        date_ent_type.append(date_count)\n",
    "        card_ent_type.append(cardinal_count)\n",
    "        gpe_ent_type.append(gpe_count)\n",
    "        fac_ent_type.append(fac_count)\n",
    "\n",
    "          \n",
    "    df['person_ent'] = person_ent_type\n",
    "    df['qty_ent'] = qty_ent_type\n",
    "    df['ordinal_ent'] = ordinal_ent_type\n",
    "    df['time_ent'] = time_ent_type\n",
    "    df['org_ent'] = org_ent_type\n",
    "    df['lang_ent'] = lang_ent_type\n",
    "    df['date_ent'] = date_ent_type\n",
    "    df['card_ent'] = card_ent_type\n",
    "    df['gpe_ent'] = gpe_ent_type\n",
    "    df['fac_ent'] = fac_ent_type\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = entityty_types(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5448, 5855)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grammars(df):\n",
    "    adv_count_list = []\n",
    "    verb_count_list = []\n",
    "    noun_count_list = []\n",
    "    propnoun_count_list = []\n",
    "    punc_count_list = []\n",
    "    #-----------------\n",
    "    part_cnt_list= []\n",
    "    adj_cnt_list= []\n",
    "    adp_cnt_list= []\n",
    "    det_cnt_list= []\n",
    "\n",
    "    for sentence in df['text_sentence']:\n",
    "        \n",
    "        advs_cnt = 0\n",
    "        verb_cnt = 0\n",
    "        noun_cnt = 0\n",
    "        propnoun_cnt = 0\n",
    "        punc_cnt = 0\n",
    "    #-----------------\n",
    "        part_cnt= 0\n",
    "        adj_cnt= 0\n",
    "        adp_cnt= 0\n",
    "        det_cnt= 0\n",
    "        \n",
    "        for token in sentence:\n",
    "            if token.pos_ == 'ADV':\n",
    "                advs_cnt +=1\n",
    "            if token.pos_ == 'VERB':\n",
    "                verb_cnt +=1\n",
    "            if token.pos_ == 'NOUN':\n",
    "                noun_cnt +=1\n",
    "            if token.pos_ == 'PROPN':\n",
    "                propnoun_cnt +=1\n",
    "            if token.pos_ == 'PUNCT':\n",
    "                punc_cnt +=1\n",
    "    #---------------------------------------\n",
    "            if token.pos_ == 'PART':\n",
    "                part_cnt +=1\n",
    "            if token.pos_ == 'ADJ':\n",
    "                adj_cnt +=1\n",
    "            if token.pos_ == 'ADP':\n",
    "                adp_cnt +=1\n",
    "            if token.pos_ == 'DET':\n",
    "                det_cnt +=1\n",
    "        \n",
    "        adv_count_list.append(advs_cnt)\n",
    "        verb_count_list.append(verb_cnt)\n",
    "        noun_count_list.append(noun_cnt)\n",
    "        propnoun_count_list.append(propnoun_cnt)\n",
    "        punc_count_list.append(punc_cnt)\n",
    "        #----------------------------------\n",
    "        part_cnt_list.append(part_cnt)\n",
    "        adj_cnt_list.append(adj_cnt)\n",
    "        adp_cnt_list.append(adp_cnt)\n",
    "        det_cnt_list.append(det_cnt)\n",
    "    #---------------------------------------    \n",
    "        \n",
    "    df['adv_count'] = adv_count_list\n",
    "    df['verb_count'] = verb_count_list\n",
    "    df['noun_count'] = noun_count_list\n",
    "    df['pronoun_count'] = propnoun_count_list\n",
    "    df['punc_count'] = punc_count_list\n",
    "\n",
    "    #-----------------\n",
    "    df['part_cnt'] = part_cnt_list\n",
    "    df['adj_cnt'] = adj_cnt_list\n",
    "    df['adp_cnt'] = adp_cnt_list\n",
    "    df['det_cnt'] = det_cnt_list\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df= grammars(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5448, 5864)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.to_csv('Check.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = df['text_source']\n",
    "X = np.array(df.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try Classifiers with default parameters and 5 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifiers_all():\n",
    "    print('\\nRandom Forest Classifier:')\n",
    "    rfc = ensemble.RandomForestClassifier()\n",
    "    rfc.fit(X_train, y_train)\n",
    "\n",
    "    rfc_train_score = cross_val_score(rfc, X_train, y_train, cv= 5)\n",
    "    rfc_test_score = cross_val_score(rfc, X_test, y_test, cv = 5)\n",
    "    #print('Training set score:',rfc_train_score )\n",
    "\n",
    "\n",
    "    print('\\t\\tAverage score on Train Data %.2f +/- %.2f'% (rfc_train_score.mean(),rfc_train_score.std() ))\n",
    "    print('\\t\\tAverage score on test Data %.2f +/- %.2f'%(rfc_test_score.mean(), rfc_test_score.std()))\n",
    "    \n",
    "    print()\n",
    "    print('Logistic Regression')   \n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    lr_train_score = cross_val_score(lr, X_train, y_train, cv= 5)\n",
    "    lr_test_score = cross_val_score(lr, X_test, y_test, cv = 5)\n",
    "    print('\\t\\tAverage score on Train Data %.2f +/- %.2f'% (lr_train_score.mean(),lr_train_score.std() ))\n",
    "    print('\\t\\tAverage score on test Data %.2f +/- %.2f'%(lr_test_score.mean(), lr_test_score.std()))\n",
    "    print()\n",
    "    print('Gradient Boosting Classifier')    \n",
    "    gbc = ensemble.GradientBoostingClassifier()\n",
    "    gbc.fit(X_train, y_train)\n",
    "    gbc_train_score = cross_val_score(gbc, X_train, y_train, cv= 5)\n",
    "    gbc_test_score = cross_val_score(gbc, X_test, y_test, cv = 5)\n",
    "\n",
    "\n",
    "    print('\\t\\tAverage score on Train Data %.2f +/- %.2f'% (gbc_train_score.mean(),gbc_train_score.std() ))\n",
    "    print('\\t\\tAverage score on test Data %.2f +/- %.2f'%(gbc_test_score.mean(), gbc_test_score.std()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classifier:\n",
      "\t\tAverage score on Train Data 0.84 +/- 0.01\n",
      "\t\tAverage score on test Data 0.83 +/- 0.01\n",
      "\n",
      "Logistic Regression\n",
      "\t\tAverage score on Train Data 0.90 +/- 0.01\n",
      "\t\tAverage score on test Data 0.89 +/- 0.02\n",
      "\n",
      "Gradient Boosting Classifier\n",
      "\t\tAverage score on Train Data 0.86 +/- 0.02\n",
      "\t\tAverage score on test Data 0.87 +/- 0.02\n"
     ]
    }
   ],
   "source": [
    "classifiers_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try hyperparameter Tuning for random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.860215053763\n",
      "{'max_depth': None, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "rfc_params  = {\n",
    "    'n_estimators':[100,200,500],\n",
    "    'max_features':['auto', 'sqrt', 'log2'],\n",
    "    'max_depth':[4, 6,7, 8, None],\n",
    "    'min_samples_split':[2, 8]\n",
    "}\n",
    "rfc_grid = GridSearchCV(ensemble.RandomForestClassifier(random_state=10), param_grid=rfc_params)\n",
    "rfc_grid.fit(X_train, y_train)\n",
    "\n",
    "print(rfc_grid.best_score_)\n",
    "print(rfc_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model with the best parameters which we got from GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: [ 0.85190039  0.87155963  0.84665793  0.87287025  0.86333771]\n",
      "\n",
      "Test set score: [ 0.84756098  0.83486239  0.81345566  0.85321101  0.88957055]\n",
      "\n",
      "Average score on Train Data 0.86 +/- 0.01\n",
      "\n",
      "Average score on test Data 0.85 +/- 0.02\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(**rfc_grid.best_params_)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc_train_score = cross_val_score(rfc, X_train, y_train, cv= 5)\n",
    "rfc_test_score = cross_val_score(rfc, X_test, y_test, cv = 5)\n",
    "print('Training set score:',rfc_train_score )\n",
    "print('\\nTest set score:',rfc_test_score )\n",
    "\n",
    "print('\\nAverage score on Train Data %.2f +/- %.2f'% (rfc_train_score.mean(),rfc_train_score.std() ))\n",
    "print('\\nAverage score on test Data %.2f +/- %.2f'%(rfc_test_score.mean(), rfc_test_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[['adv_count','verb_count','noun_count','pronoun_count','punc_count','part_cnt','adj_cnt','adp_cnt','det_cnt']] = \\\n",
    "StandardScaler().fit_transform(df[['adv_count','verb_count','noun_count','pronoun_count','punc_count','part_cnt','adj_cnt','adp_cnt','det_cnt']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[['sent_length']]  = StandardScaler().fit_transform(df[['sent_length']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[['person_ent','qty_ent','ordinal_ent','time_ent','org_ent','lang_ent','date_ent','card_ent','gpe_ent','fac_ent']] = \\\n",
    "StandardScaler().fit_transform(df[['person_ent','qty_ent','ordinal_ent','time_ent','org_ent','lang_ent','date_ent','card_ent','gpe_ent','fac_ent']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = df['text_source']\n",
    "X = np.array(df.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: [ 0.89252949  0.8938401   0.88728702  0.92398427  0.91064389]\n",
      "\n",
      "Test set score: [ 0.91158537  0.88685015  0.86544343  0.88685015  0.90490798]\n",
      "\n",
      "Average score on Train Data 0.90 +/- 0.01\n",
      "\n",
      "Average score on test Data 0.89 +/- 0.02\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_train_score = cross_val_score(lr, X_train, y_train, cv= 5)\n",
    "lr_test_score = cross_val_score(lr, X_test, y_test, cv = 5)\n",
    "print('Training set score:',lr_train_score )\n",
    "print('\\nTest set score:',lr_test_score )\n",
    "\n",
    "print('\\nAverage score on Train Data %.2f +/- %.2f'% (lr_train_score.mean(),lr_train_score.std() ))\n",
    "print('\\nAverage score on test Data %.2f +/- %.2f'%(lr_test_score.mean(), lr_test_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter  {'C': 1, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "parameters =[ {'C': [0.01, 0.1, 1, 10, 100],'solver':['liblinear'],'penalty':['l1', 'l2'],'fit_intercept':[True]},\n",
    "            {'C': [0.01, 0.1, 1, 10, 100],'solver':['lbfgs','newton-cg'],'fit_intercept':[True]}\n",
    "            ]\n",
    "\n",
    "gr_logr = GridSearchCV(lr,param_grid = parameters )\n",
    "gr_logr.fit(X_train,y_train)\n",
    "print('Best Parameter ', gr_logr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: [ 0.89252949  0.8938401   0.88728702  0.92398427  0.91064389]\n",
      "\n",
      "Test set score: [ 0.91158537  0.88685015  0.86544343  0.88685015  0.90490798]\n",
      "\n",
      "Average score on Train Data 0.90 +/- 0.01\n",
      "\n",
      "Average score on test Data 0.89 +/- 0.02\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(**gr_logr.best_params_, random_state = 10)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_train_score = cross_val_score(lr, X_train, y_train, cv= 5)\n",
    "lr_test_score = cross_val_score(lr, X_test, y_test, cv = 5)\n",
    "print('Training set score:',lr_train_score )\n",
    "print('\\nTest set score:',lr_test_score )\n",
    "\n",
    "print('\\nAverage score on Train Data %.2f +/- %.2f'% (lr_train_score.mean(),lr_train_score.std() ))\n",
    "print('\\nAverage score on test Data %.2f +/- %.2f'%(lr_test_score.mean(), lr_test_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3813, 5862) (3813,)\n",
      "Training set score: 0.682926829268\n",
      "\n",
      "Test set score: 0.698470948012\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "train = svc.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', svc.score(X_train, y_train))\n",
    "print('\\nTest set score:', svc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "We tried adding more features like including grammar, phrases, POS and sentence-level features like number of words, amount of punctuation, length of previous and next sentences, words repeated from one sentence to the next etc. \n",
    "Also used cross_validation with 5 folds.\n",
    " \n",
    "After all these improvements, For random forest classifier, we got 2% increase in the score, while for logistic regression, we got 1% increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CHALLENGE 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milton vs. Carroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load in and clean a new book, using our text_cleaner function and the spacy load function\n",
    "paradise = gutenberg.raw('milton-paradise.txt')\n",
    "paradise = re.sub(r'CHAPTER .*', '', paradise)\n",
    "paradise = text_cleaner(paradise)\n",
    "\n",
    "#Spacy load\n",
    "paradise_doc = nlp(paradise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
       "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
       "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
       "3                                      (Oh, dear, !)  Carroll\n",
       "4                         (I, shall, be, late, !, ')  Carroll"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract and store sentences from spacy doc\n",
    "paradise_sents = [[sent, 'Milton'] for sent in paradise_doc.sents]\n",
    "\n",
    "#Add the paradise sentences to our existing sentences DF\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents + paradise_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gyans\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n"
     ]
    }
   ],
   "source": [
    "paradise_sentences = pd.DataFrame(paradise_sents)\n",
    "paradise_bow = bow_features(paradise_sentences, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paradise_bow = entityty_types(paradise_bow)\n",
    "paradise_bow= grammars(paradise_bow)\n",
    "paradise_bow.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alice_wc = word_counts[word_counts.text_source == 'Carroll']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gyans\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:2754: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "alice_wc.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paradise_bow2 = paradise_bow.iloc[:,0:8953]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3241, 8953)\n",
      "(1740, 8953)\n"
     ]
    }
   ],
   "source": [
    "print(paradise_bow2.shape)\n",
    "print(alice_wc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Identifying variables\n",
    "X_paradise = paradise_bow2.drop(['text_sentence','text_source'], 1)\n",
    "y_paradise = paradise_bow2.text_source\n",
    "\n",
    "\n",
    "X_alice = alice_wc.drop(['text_sentence','text_source'], 1)\n",
    "y_alice = alice_wc.text_source\n",
    "\n",
    "# Combine the Paradise sentence data with the Alice data from the test set.\n",
    "X_pa = pd.concat([X_paradise, X_alice], 0)\n",
    "y_pa = pd.concat([y_paradise, y_alice], 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "X_train_pa, X_test_pa, y_train_pa, y_test_pa = train_test_split(X_pa, y_pa, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: [ 0.95986622  0.95652174  0.9548495   0.96314908  0.94304858]\n",
      "\n",
      "Test set score: [ 0.94235589  0.94987469  0.94235589  0.94221106  0.93969849]\n",
      "\n",
      "Average score on Train Data 0.96 +/- 0.01\n",
      "\n",
      "Average score on test Data 0.94 +/- 0.00\n"
     ]
    }
   ],
   "source": [
    "# Model.\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_pa, y_train_pa)\n",
    "lr_train_score = cross_val_score(lr, X_train_pa, y_train_pa, cv= 5)\n",
    "lr_test_score = cross_val_score(lr, X_test_pa, y_test_pa, cv = 5)\n",
    "print('Training set score:',lr_train_score )\n",
    "print('\\nTest set score:',lr_test_score )\n",
    "\n",
    "print('\\nAverage score on Train Data %.2f +/- %.2f'% (lr_train_score.mean(),lr_train_score.std() ))\n",
    "print('\\nAverage score on test Data %.2f +/- %.2f'%(lr_test_score.mean(), lr_test_score.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Carroll</th>\n",
       "      <th>Milton</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>660</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Milton</th>\n",
       "      <td>45</td>\n",
       "      <td>1238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        Carroll  Milton\n",
       "text_source                 \n",
       "Carroll          660      50\n",
       "Milton            45    1238"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pa_predicted = lr.predict(X_test_pa)\n",
    "pd.crosstab(y_test_pa, lr_pa_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These same common words and features are pretty good at separating sentences by Carroll and Milton. This means that the features are able to identify Carroll from other works. Now, let's see if the same features are able to identify Austen from other works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milton vs. Austen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3708, 8953)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persuasion_wc = word_counts[word_counts.text_source == 'Austen']\n",
    "persuasion_wc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: [ 0.94850299  0.94004796  0.95203837  0.96038415  0.95438175]\n",
      "\n",
      "Test set score: [ 0.92625899  0.93345324  0.92266187  0.96043165  0.94964029]\n",
      "\n",
      "Average score on Train Data 0.95 +/- 0.01\n",
      "\n",
      "Average score on test Data 0.94 +/- 0.01\n"
     ]
    }
   ],
   "source": [
    "# Identifying variables\n",
    "X_paradise = paradise_bow2.drop(['text_sentence','text_source'], 1)\n",
    "y_paradise = paradise_bow2.text_source\n",
    "\n",
    "\n",
    "X_persuasion = persuasion_wc.drop(['text_sentence','text_source'], 1)\n",
    "y_persuasion = persuasion_wc.text_source\n",
    "\n",
    "# Combine the Paradise sentence data with the Alice data from the test set.\n",
    "X_pp = pd.concat([X_paradise, X_persuasion], 0)\n",
    "y_pp = pd.concat([y_paradise, y_persuasion], 0)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train_pp, X_test_pp, y_train_pp, y_test_pp = train_test_split(X_pp, y_pp, test_size=0.4, random_state=0)\n",
    "\n",
    "# Model.\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_pp, y_train_pp)\n",
    "lr_train_score = cross_val_score(lr, X_train_pp, y_train_pp, cv= 5)\n",
    "lr_test_score = cross_val_score(lr, X_test_pp, y_test_pp, cv = 5)\n",
    "print('Training set score:',lr_train_score )\n",
    "print('\\nTest set score:',lr_test_score )\n",
    "\n",
    "print('\\nAverage score on Train Data %.2f +/- %.2f'% (lr_train_score.mean(),lr_train_score.std() ))\n",
    "print('\\nAverage score on test Data %.2f +/- %.2f'%(lr_test_score.mean(), lr_test_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Milton</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>1416</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Milton</th>\n",
       "      <td>77</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        Austen  Milton\n",
       "text_source                \n",
       "Austen         1416      64\n",
       "Milton           77    1223"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pp_predicted = lr.predict(X_test_pp)\n",
    "pd.crosstab(y_test_pp, lr_pp_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same feature space is able to distinguish between Austen and Milton. This means that, in general, a set of common words, along with sentence length, and the numbers of different parts of speech, are enough to tell which author wrote a particular sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion\n",
    "The same feature space is able to distinguish between Austen and Milton or y Carroll and Milton. \n",
    "This time we got scores of 94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
